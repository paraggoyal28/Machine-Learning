{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpld3\n",
    "mpld3.enable_notebook()\n",
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "            \n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "from scipy import stats #Analysis \n",
    "            \n",
    "#import the necessary modelling algos.\n",
    "            \n",
    "#classifiaction.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "            \n",
    "#regression\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor,BaggingRegressor,GradientBoostingRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "            \n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "            \n",
    "#evaluation metrics\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error # for regression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score  # for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output all lines\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Pclass.value_counts(normalize=True).plot(kind=\"bar\")\n",
    "\n",
    "\n",
    "plt.scatter(df.Survived,df.Age, alpha=0.5)\n",
    "\n",
    "\n",
    "for x in [1,2,3]:\n",
    "    df.Age[df.Pclass == x].plot(kind=\"kde\")\n",
    "plt.legend((\"1st\", \"2nd\", \"3rd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all columns\n",
    "import pandas as pd\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1, 2, 0.3) \n",
    "# >>  [1.  1.3 1.6 1.9]\n",
    "\n",
    "np.linspace(1, 2, 7)\n",
    "# >>  [1. 1.16666667 1.33333333 1.5  1.66666667 1.83333333     2.        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_sum = lambda x, y: x + y\n",
    "reduce(lambda_sum, [1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check NULL values\n",
    "df.isnull().values.any()\n",
    "\n",
    "#check NULL values count\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "temp = df.copy()\n",
    "temp.iloc[:,1] = label_encoder.fit_transform(df.iloc[:,1])    #1 is column index\n",
    "temp.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "standard_scaler = StandardScaler()\n",
    "normalizer = Normalizer()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "print(standard_scaler.fit_transform(X))\n",
    "print(normalizer.fit_transform(X))\n",
    "print(min_max_scaler.fit_transform(X))\n",
    "\n",
    "\n",
    "# One hot encoding\n",
    "pd.get_dummies(df.iloc[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Linear Regression with summary\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std\n",
    "\n",
    "feature_cols = ['Reputation',  'Views', 'tag_1', 'tag_2', 'tag_3', 'tag_4', 'tag_5', 'tag_6', 'tag_7', 'tag_8', 'tag_9']\n",
    "\n",
    "X = temp[feature_cols]\n",
    "y = temp.Upvotes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "model1=sm.OLS(y_train,X_train)\n",
    "result=model1.fit()\n",
    "\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#linear regressio with gradient descent\n",
    "\n",
    "def linear_regression(X, y, m_current=0, b_current=0, epochs=1000, learning_rate=0.0001):\n",
    "    N = float(len(y))\n",
    "    for i in range(epochs):  \n",
    "        y_current = (m_current * X) + b_current\n",
    "        cost = sum([data**2 for data in (y-y_current)]) / N\n",
    "        m_gradient = -(2/N) * sum(X * (y - y_current))\n",
    "        b_gradient = -(2/N) * sum(y - y_current)\n",
    "        m_current = m_current - (learning_rate * m_gradient)\n",
    "        b_current = b_current - (learning_rate * b_gradient)\n",
    "    return m_current, b_current, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### mean square error and r2_score\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_predict = slr.predict(X_test) # predict the Y based on the model\n",
    "mean_squared_error = mean_squared_error(y_test,y_predict) # calculate mean square error\n",
    "r2_score = r2_score(y_test,y_predict) #calculate r square\n",
    "\n",
    "print ('mean square error:',mean_squared_error )\n",
    "print ('r square:',r2_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_prob)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "# calculate AUC\n",
    "print metrics.roc_auc_score(y_test, y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the p-values for the model coefficients\n",
    "lm1.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You see number of unique item for Species with command below:\n",
    "dataset['Species'].unique()\n",
    "\n",
    "# grouping\n",
    "dataset.groupby('Species').count()\n",
    "\n",
    "#where\n",
    "dataset.where(dataset ['Species']=='Iris-setosa') #or\n",
    "dataset[dataset['SepalLengthCm']>7.2]\n",
    "\n",
    "# Seperating the data into dependent and independent variables\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data according to dependent and in dependent variable\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scalers\n",
    "# Standard scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaled_df = scaler.fit_transform(df)\n",
    "\n",
    "#min-max Scalar\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Robust scaler\n",
    "scaler = preprocessing.RobustScaler()\n",
    "\n",
    "#normalizer\n",
    "scaler = preprocessing.Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot in sns\n",
    "\n",
    "# Modify the graph above by assigning each species an individual color.\n",
    "sns.FacetGrid(dataset, hue=\"Species\", size=5) \\\n",
    "   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n",
    "   .add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#### Spelling Corrector\n",
    "\n",
    "\n",
    "import re, collections\n",
    "\n",
    "def tokens(text): \n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower()) \n",
    "\n",
    "WORDS = tokens(file('big.txt').read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)\n",
    "\n",
    "# top 10 words in corpus\n",
    "print WORD_COUNTS.most_common(10)\n",
    "\n",
    "\n",
    "def known(words):\n",
    "    \"\"\"\n",
    "    Return the subset of words that are actually \n",
    "    in our WORD_COUNTS dictionary.\n",
    "    \"\"\"\n",
    "    return {w for w in words if w in WORD_COUNTS}\n",
    "\n",
    "\n",
    "def edits0(word): \n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away \n",
    "    from the input word (i.e., the word itself).\n",
    "    \"\"\"\n",
    "    return {word}\n",
    "\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edit away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        Return a list of all possible (first, rest) pairs \n",
    "        that the input word is made of.\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]\n",
    "                \n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "\n",
    "def edits2(word):\n",
    "    \"\"\"Return all strings that are two edits away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}\n",
    "    \n",
    "    \n",
    "def correct(word):\n",
    "    \"\"\"\n",
    "    Get the best correct spelling for the input word\n",
    "    \"\"\"\n",
    "    # Priority is for edit distance 0, then 1, then 2\n",
    "    # else defaults to the input word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)\n",
    "\n",
    "\n",
    "def correct_match(match):\n",
    "    \"\"\"\n",
    "    Spell-correct word in match, \n",
    "    and preserve proper upper/lower/title case.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = match.group()\n",
    "    def case_of(text):\n",
    "        \"\"\"\n",
    "        Return the case-function appropriate \n",
    "        for text: upper, lower, title, or just str.:\n",
    "            \"\"\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "    \n",
    "def correct_text_generic(text):\n",
    "    \"\"\"\n",
    "    Correct all the words within a text, \n",
    "    returning the corrected text.\n",
    "    \"\"\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "\n",
    "\n",
    "print correct_text_generic('fianlly')\n",
    "\n",
    "\n",
    "from pattern.en import suggest\n",
    "\n",
    "print suggest('fianlly')\n",
    "print suggest('flaot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion using label encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "clean_df = train_set.copy()\n",
    "\n",
    "for f in clean_df.columns:\n",
    "    if clean_df[f].dtype == 'object':\n",
    "        label = preprocessing.LabelEncoder()\n",
    "        label.fit(list(clean_df[f].values))\n",
    "        clean_df[f] = label.transform(list(clean_df[f].values))\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "GradientBoostingClassifier(criterion=’friedman_mse’, init=None, learning_rate=0.1, loss=’deviance’, max_depth=3,\n",
    "max_features=None, max_leaf_nodes=None, min_impurity_split=1e-07, min_samples_leaf=1, min_samples_split=2,\n",
    "min_weight_fraction_leaf=0.0, n_estimators=100, presort=’auto’, random_state=None, subsample=1.0,\n",
    "verbose=0, warm_start=False)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "roc_auc\n",
    "\n",
    "\n",
    "> 0.79286211093722836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing text with @\n",
    "\n",
    "combi['tidy_tweet'] = np.vectorize(remove_pattern)(combi['tweet'], \"@[\\w]*\") \n",
    "combi.head()\n",
    "\n",
    "#Removing Punctuations, Numbers, and Special Characters\n",
    "combi['tidy_tweet'] = combi['tidy_tweet'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "combi.head(10)\n",
    "\n",
    "#Removing Short Words\n",
    "combi['tidy_tweet'] = combi['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "#Text Normalization\n",
    "tokenized_tweet = combi['tidy_tweet'].apply(lambda x: x.split()) # tokenizing\n",
    "\n",
    "\n",
    "# normalization of tokenised or stemming\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
